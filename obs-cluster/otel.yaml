mode: daemonset

service:
  enabled: true
  type: LoadBalancer

image:
  repository: "otel/opentelemetry-collector-contrib"


extraEnvs:
  - name: "K8S_NODE_NAME"
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: OTELPASS
    valueFrom:
      secretKeyRef:
        name: otel-secret
        key: otel-pass
  - name: OTELUSERID
    valueFrom:
      secretKeyRef:
        name: otel-secret
        key: otel-userid
### kubectl command to create secret
# kubectl create secret generic otel-secret --from-literal=otel-secret=otel-secret


tolerations:
  - key: "node-role.kubernetes.io/control-plane"
    operator: "Exists"
    effect: "NoSchedule"
clusterRole:
  create: true
  rules:
    - apiGroups: ["*"]
      resources: ["*"]
      verbs: ["*"]

affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: az
          operator: In
          values: [ "a","b","c"]
presets:
  hostMetrics:
    enabled: false
  kubeletMetrics:
    enabled: false
  kubernetesAttributes:
    enabled: true



config:    
  # Tested with OpenTelemetry Collector Contrib v0.98.0
  extensions:
    health_check:
      #
  receivers:
    k8s_events:
      auth_type: kubeConfig
    prometheus:
      config:
        global:
          scrape_interval: 60s
          scrape_timeout: 10s
          external_labels:
            cluster: "obs-cluster"
        scrape_configs:
          - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            job_name: integrations/kubernetes/cadvisor
            kubernetes_sd_configs:
              - role: node
            relabel_configs:
              - replacement: kubernetes.default.svc.cluster.local:443
                target_label: __address__
              - regex: (.+)
                replacement: /api/v1/nodes/$${1}/proxy/metrics/cadvisor
                source_labels:
                  - __meta_kubernetes_node_name
                target_label: __metrics_path__
            metric_relabel_configs:
              - source_labels: [__name__]
                action: keep
                regex: 'container_cpu_cfs_periods_total|container_cpu_cfs_throttled_periods_total|container_cpu_usage_seconds_total|container_fs_reads_bytes_total|container_fs_reads_total|container_fs_writes_bytes_total|container_fs_writes_total|container_memory_cache|container_memory_rss|container_memory_swap|container_memory_working_set_bytes|container_network_receive_bytes_total|container_network_receive_packets_dropped_total|container_network_receive_packets_total|container_network_transmit_bytes_total|container_network_transmit_packets_dropped_total|container_network_transmit_packets_total|machine_memory_bytes'
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: false
              server_name: kubernetes

          - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            job_name: integrations/kubernetes/kubelet
            kubernetes_sd_configs:
              - role: node
            relabel_configs:
              - replacement: kubernetes.default.svc.cluster.local:443
                target_label: __address__
              - regex: (.+)
                replacement: /api/v1/nodes/$${1}/proxy/metrics
                source_labels:
                  - __meta_kubernetes_node_name
                target_label: __metrics_path__
            metric_relabel_configs:
              - source_labels: [__name__]
                action: keep
                regex: 'container_cpu_usage_seconds_total|kubelet_certificate_manager_client_expiration_renew_errors|kubelet_certificate_manager_client_ttl_seconds|kubelet_certificate_manager_server_ttl_seconds|kubelet_cgroup_manager_duration_seconds_bucket|kubelet_cgroup_manager_duration_seconds_count|kubelet_node_config_error|kubelet_node_name|kubelet_pleg_relist_duration_seconds_bucket|kubelet_pleg_relist_duration_seconds_count|kubelet_pleg_relist_interval_seconds_bucket|kubelet_pod_start_duration_seconds_bucket|kubelet_pod_start_duration_seconds_count|kubelet_pod_worker_duration_seconds_bucket|kubelet_pod_worker_duration_seconds_count|kubelet_running_container_count|kubelet_running_containers|kubelet_running_pod_count|kubelet_running_pods|kubelet_runtime_operations_errors_total|kubelet_runtime_operations_total|kubelet_server_expiration_renew_errors|kubelet_volume_stats_available_bytes|kubelet_volume_stats_capacity_bytes|kubelet_volume_stats_inodes|kubelet_volume_stats_inodes_used|kubernetes_build_info|namespace_workload_pod|rest_client_requests_total|storage_operation_duration_seconds_count|storage_operation_errors_total|volume_manager_total_volumes'
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: false
              server_name: kubernetes

          - job_name: integrations/kubernetes/kube-state-metrics
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - action: keep
                regex: kube-state-metrics
                source_labels:
                  - __meta_kubernetes_pod_label_app_kubernetes_io_name
            metric_relabel_configs:
              - source_labels: [__name__]
                action: keep
                regex: 'kube_daemonset.*|kube_deployment_metadata_generation|kube_deployment_spec_replicas|kube_deployment_status_observed_generation|kube_deployment_status_replicas_available|kube_deployment_status_replicas_updated|kube_horizontalpodautoscaler_spec_max_replicas|kube_horizontalpodautoscaler_spec_min_replicas|kube_horizontalpodautoscaler_status_current_replicas|kube_horizontalpodautoscaler_status_desired_replicas|kube_job.*|kube_namespace_status_phase|kube_node.*|kube_persistentvolumeclaim_resource_requests_storage_bytes|kube_pod_container_info|kube_pod_container_resource_limits|kube_pod_container_resource_requests|kube_pod_container_status_last_terminated_reason|kube_pod_container_status_restarts_total|kube_pod_container_status_waiting_reason|kube_pod_info|kube_pod_owner|kube_pod_start_time|kube_pod_status_phase|kube_pod_status_reason|kube_replicaset.*|kube_resourcequota|kube_statefulset.*'

          - job_name: integrations/node_exporter
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - action: keep
                regex: prometheus-node-exporter.*
                source_labels:
                  - __meta_kubernetes_pod_label_app_kubernetes_io_name
              - action: replace
                source_labels:
                  - __meta_kubernetes_pod_node_name
                target_label: instance
              - action: replace
                source_labels:
                  - __meta_kubernetes_namespace
                target_label: namespace
            metric_relabel_configs:
              - source_labels: [__name__]
                action: keep
                regex: 'node_cpu.*|node_exporter_build_info|node_filesystem.*|node_memory.*|process_cpu_seconds_total|process_resident_memory_bytes'
    otlp:
      protocols: 
      # https://github.com/open-telemetry/opentelemetry-collector/tree/main/receiver/otlpreceiver
        grpc:  {}
        http: {}

  processors:
    resource:
      attributes:
      - action: insert
        from_attribute: k8s.pod.uid
        key: service.instance.id
      - key: cluster_name
        action: insert
        value: "obs-cluster"
      - key: k8s.cluster.name
        action: insert
        value: "obs-cluster"
      - key: cluster
        action: insert
        value: "obs-cluster"
    k8sattributes/inbound:
      passthrough: true
      #
    transform:
      error_mode: ignore
      trace_statements:
        - context: span
          statements:
            # could be removed when https://github.com/vercel/next.js/pull/64852 is fixed upstream
            - replace_pattern(name, "\\?.*", "")
            - replace_match(name, "GET /api/products/*", "GET /api/products/{productId}")
    batch:
      # https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor/batchprocessor
      send_batch_size: 1000
      send_batch_max_size: 1000


  exporters:
    debug: {}
    otlphttp/grafana_cloud:
      # https://github.com/open-telemetry/opentelemetry-collector/tree/main/exporter/otlphttpexporter
      endpoint: "https://otlp-gateway-prod-us-west-0.grafana.net/otlp"
      auth:
        authenticator: basicauth/grafana_cloud
      
      
  extensions:
    basicauth/grafana_cloud:
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/basicauthextension
      client_auth:
        username: ${OTELUSERID}
        password: ${OTELPASS}

  connectors:
    grafanacloud:
      # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/connector/grafanacloudconnector
      host_identifiers: ["host.name"]

  service:
    extensions: [basicauth/grafana_cloud,health_check,]
    pipelines:
      traces:
        receivers: [otlp]
        processors: [transform,k8sattributes/inbound,batch]
        exporters: [otlphttp/grafana_cloud, grafanacloud,debug]
      metrics:
        receivers: [otlp,grafanacloud,prometheus]
        processors: [transform,k8sattributes/inbound,resource,batch]
        exporters: [otlphttp/grafana_cloud,debug]
      logs:
        receivers: [otlp,k8s_events]
        processors: [transform,k8sattributes/inbound,resource,batch]
        exporters: [otlphttp/grafana_cloud,debug]
